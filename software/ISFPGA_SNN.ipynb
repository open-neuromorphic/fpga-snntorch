{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Open-Source Neuromorphic Circuit Design\n",
        "## By Jason K. Eshraghian (www.ncg.ucsc.edu)\n",
        "\n",
        "\n",
        "[<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/snntorch_alpha_w.png?raw=true' width=\"200\">](https://github.com/jeshraghian/snntorch/)"
      ],
      "metadata": {
        "id": "8w6lhn7H8fW5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BlTqunB73-t"
      },
      "outputs": [],
      "source": [
        "!pip install snntorch --quiet # shift + enter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*What will I learn?*\n",
        "\n",
        "1. Train an SNN classifier using snnTorch\n",
        "2. Hardware Friendly Training\n",
        "  - Weight Quantization with Brevitas\n",
        "  - Stateful Quantization\n",
        "3. Manual Non-Idealities, e.g., read noise"
      ],
      "metadata": {
        "id": "xLlnINAI9mgJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Train an SNN Classifier using snnTorch\n",
        "## 1.1 Imports\n"
      ],
      "metadata": {
        "id": "-CS50cwuCW6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# snntorch imports\n",
        "import snntorch as snn\n",
        "from snntorch import functional as SF\n",
        "\n",
        "# pytorch imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# data manipulation\n",
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "# plotting\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import HTML"
      ],
      "metadata": {
        "id": "H_TzogsCCcSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Boilerplate: DataLoading the MNIST Dataset"
      ],
      "metadata": {
        "id": "nftOdpyAGv7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dataloader arguments\n",
        "batch_size = 128\n",
        "data_path='/data/mnist'\n",
        "\n",
        "dtype = torch.float\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "## if you're on M1 or M2 GPU:\n",
        "# device = torch.device(\"mps\")"
      ],
      "metadata": {
        "id": "SsM2Z5NXGu5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a transform\n",
        "transform = transforms.Compose([\n",
        "            transforms.Resize((28, 28)),\n",
        "            transforms.Grayscale(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0,), (1,))])\n",
        "\n",
        "mnist_train = datasets.MNIST(data_path, train=True, download=True, transform=transform)\n",
        "mnist_test = datasets.MNIST(data_path, train=False, download=True, transform=transform)"
      ],
      "metadata": {
        "id": "XqbYptgDHUPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoaders\n",
        "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True, drop_last=True)"
      ],
      "metadata": {
        "id": "jSlS3gWZHXI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Construct SNN Model"
      ],
      "metadata": {
        "id": "SJVhfNukHbsp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Network Architecture\n",
        "num_inputs =\n",
        "num_hidden =\n",
        "num_outputs =\n",
        "\n",
        "# Temporal Dynamics\n",
        "num_steps =\n",
        "beta ="
      ],
      "metadata": {
        "id": "uu324fr_HhxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from snntorch import surrogate\n",
        "\n",
        "# Define Network\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Initialize layers\n",
        "        self.fc1 =\n",
        "        self.lif1 =\n",
        "        self.fc2 =\n",
        "        self.lif2 =\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # Initialize hidden states at t=0\n",
        "        mem1 = self.lif1.init_leaky()\n",
        "        mem2 = self.lif2.init_leaky()\n",
        "\n",
        "        # Record the final layer\n",
        "        spk2_rec = []\n",
        "        mem2_rec = []\n",
        "\n",
        "        # time-loop\n",
        "        for step in range(num_steps):\n",
        "          cur1 = self.fc1(...) # batch: 128 x 784\n",
        "          spk1, mem1 = self.lif1(...)\n",
        "          cur2 = self.fc2(...)\n",
        "          spk2, mem2 = self.lif2(...)\n",
        "\n",
        "          # store in list\n",
        "          spk2_rec.append(spk2)\n",
        "          mem2_rec.append(mem2)\n",
        "\n",
        "        return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0) # time-steps x batch x num_out\n",
        "\n",
        "# Load the network onto CUDA if available\n",
        "net = Net().to(device)"
      ],
      "metadata": {
        "id": "CkM1Z1EjHeW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4 Training the SNN"
      ],
      "metadata": {
        "id": "p8qBw03rHpn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(model, dataloader, num_epochs=1):\n",
        "  loss = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=5e-4, betas=(0.9, 0.999))\n",
        "  counter = 0\n",
        "\n",
        "  # Outer training loop\n",
        "  for epoch in range(num_epochs):\n",
        "      train_batch = iter(dataloader)\n",
        "\n",
        "      # Minibatch training loop\n",
        "      for data, targets in train_batch:\n",
        "          data = data.to(device)\n",
        "          targets = targets.to(device)\n",
        "\n",
        "          # forward pass\n",
        "          model.train()\n",
        "          spk_rec, _ = model(data)\n",
        "\n",
        "          # initialize the loss & sum over time\n",
        "          loss_val = torch.zeros((1), dtype=dtype, device=device)\n",
        "          loss_val = loss(spk_rec.sum(0), targets) # batch x num_out\n",
        "\n",
        "          # Gradient calculation + weight update\n",
        "          optimizer.zero_grad()\n",
        "          loss_val.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          # Print train/test loss/accuracy\n",
        "          if counter % 10 == 0:\n",
        "              print(f\"Iteration: {counter} \\t Train Loss: {loss_val.item()}\")\n",
        "          counter += 1\n",
        "\n",
        "          if counter == 100:\n",
        "            break\n",
        "\n",
        "training_loop(net, train_loader)"
      ],
      "metadata": {
        "id": "1telBMU-HrIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def measure_accuracy(model, dataloader):\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    running_length = 0\n",
        "    running_accuracy = 0\n",
        "\n",
        "    for data, targets in iter(dataloader):\n",
        "      data = data.to(device)\n",
        "      targets = targets.to(device)\n",
        "\n",
        "      # forward-pass\n",
        "      spk_rec, _ = model(data)\n",
        "      spike_count = spk_rec.sum(0) # batch x num_outputs\n",
        "      _, max_spike = spike_count.max(1)\n",
        "\n",
        "      # correct classes for one batch\n",
        "      num_correct = (max_spike == targets).sum()\n",
        "\n",
        "      # total accuracy\n",
        "      running_length += len(targets)\n",
        "      running_accuracy += num_correct\n",
        "\n",
        "    accuracy = (running_accuracy / running_length)\n",
        "\n",
        "    return accuracy.item()\n"
      ],
      "metadata": {
        "id": "nHsdkuSlIS1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Test set accuracy: {measure_accuracy(net, test_loader)}\")"
      ],
      "metadata": {
        "id": "oJHAltRCKGyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Hardware Friendly Training\n",
        "## 2.1 Weight Quantization"
      ],
      "metadata": {
        "id": "Z9vrb2zUD6S-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install brevitas --quiet"
      ],
      "metadata": {
        "id": "icK4WzuL-2QA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just replace all `nn.Linear` layers with `qnn.QuantLinear(num_inputs, num_outputs, weight_bit_width, bias)`."
      ],
      "metadata": {
        "id": "idiLnVjJGJAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import brevitas.nn as qnn\n",
        "\n",
        "# Define Network\n",
        "class QuantNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Initialize layers\n",
        "        self.fc1 =\n",
        "        self.lif1 =\n",
        "        self.fc2 =\n",
        "        self.lif2 =\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # Initialize hidden states at t=0\n",
        "        mem1 = self.lif1.init_leaky()\n",
        "        mem2 = self.lif2.init_leaky()\n",
        "\n",
        "        # Record the final layer\n",
        "        spk2_rec = []\n",
        "        mem2_rec = []\n",
        "\n",
        "        for step in range(num_steps):\n",
        "            cur1 = self.fc1(x.flatten(1))\n",
        "            spk1, mem1 = self.lif1(cur1, mem1)\n",
        "            cur2 = self.fc2(spk1)\n",
        "            spk2, mem2 = self.lif2(cur2, mem2)\n",
        "            spk2_rec.append(spk2)\n",
        "            mem2_rec.append(mem2)\n",
        "\n",
        "        return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)\n",
        "\n",
        "# Load the network onto CUDA if available\n",
        "qnet = QuantNet().to(device)"
      ],
      "metadata": {
        "id": "PiZYTMA6D-YL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_loop(qnet, train_loader)\n",
        "print(f\"Test set accuracy: {measure_accuracy(qnet, test_loader)}\")"
      ],
      "metadata": {
        "id": "PocSa27MOOoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Stateful Quantization\n",
        "\n"
      ],
      "metadata": {
        "id": "JvRzLHdjD-6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from snntorch.functional import quant\n",
        "\n",
        "# Define Network\n",
        "class SquatNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Define state quantization parameters\n",
        "        q_lif = quant.state_quant(num_bits=4, uniform=True)\n",
        "\n",
        "        # Initialize layers\n",
        "        self.fc1 =\n",
        "        self.lif1 =\n",
        "        self.fc2 =\n",
        "        self.lif2 =\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # Initialize hidden states at t=0\n",
        "        mem1 = self.lif1.init_leaky()\n",
        "        mem2 = self.lif2.init_leaky()\n",
        "\n",
        "        # Record the final layer\n",
        "        spk2_rec = []\n",
        "        mem2_rec = []\n",
        "\n",
        "        for step in range(num_steps):\n",
        "            cur1 = self.fc1(x.flatten(1))\n",
        "            spk1, mem1 = self.lif1(cur1, mem1)\n",
        "            cur2 = self.fc2(spk1)\n",
        "            spk2, mem2 = self.lif2(cur2, mem2)\n",
        "            spk2_rec.append(spk2)\n",
        "            mem2_rec.append(mem2)\n",
        "\n",
        "        return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)\n",
        "\n",
        "# Load the network onto CUDA if available\n",
        "sqnet = SquatNet().to(device)"
      ],
      "metadata": {
        "id": "tAaafUczEAu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_loop(sqnet, train_loader)\n",
        "print(f\"Test set accuracy: {measure_accuracy(sqnet, test_loader)}\")"
      ],
      "metadata": {
        "id": "0zfo0h6AQDzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Manual Non-Idealities\n",
        "## 3.1 Noise Injection"
      ],
      "metadata": {
        "id": "EZAFVgHW4M2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Network\n",
        "class MemNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        q_lif = quant.state_quant(num_bits=4, uniform=True)\n",
        "\n",
        "        # Initialize layers\n",
        "        self.fc1 = qnn.QuantLinear(num_inputs, num_hidden, weight_bit_width=8, bias=False)\n",
        "        self.lif1 = snn.Leaky(beta=beta, state_quant=q_lif)\n",
        "        self.fc2 = qnn.QuantLinear(num_hidden, num_outputs, weight_bit_width=8, bias=False)\n",
        "        self.lif2 = snn.Leaky(beta=beta, state_quant=q_lif)\n",
        "\n",
        "        # Introduce readout noise\n",
        "        self.lif1_rand = torch.randn((num_hidden), device=device)\n",
        "        self.lif2_rand = torch.randn((num_outputs), device=device)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # Initialize hidden states at t=0\n",
        "        mem1 = self.lif1.init_leaky()\n",
        "        mem2 = self.lif2.init_leaky()\n",
        "\n",
        "        # Record the final layer\n",
        "        spk2_rec = []\n",
        "        mem2_rec = []\n",
        "\n",
        "        for step in range(num_steps):\n",
        "            cur1 = self.fc1(x.flatten(1))\n",
        "            spk1, mem1 = self.lif1(cur1, mem1)\n",
        "            mem1 = mem1 + (mem1 * self.lif1_rand) # apply noise\n",
        "            cur2 = self.fc2(spk1)\n",
        "            spk2, mem2 = self.lif2(cur2, mem2)\n",
        "            mem2 = mem2 + (mem2 * self.lif2_rand) # apply noise\n",
        "            spk2_rec.append(spk2)\n",
        "            mem2_rec.append(mem2)\n",
        "\n",
        "        return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)\n",
        "\n",
        "# Load the network onto CUDA if available\n",
        "memnet = MemNet().to(device)"
      ],
      "metadata": {
        "id": "-HEhzeA02Ueg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_loop(memnet, train_loader)\n",
        "print(f\"Test set accuracy: {measure_accuracy(memnet, test_loader)}\")"
      ],
      "metadata": {
        "id": "V5havFWd3c-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ADC saturation limits using `torch.clamp(input, min=None, max=None)`\n",
        "* Weight noise by applying random matrix to weight matrices\n",
        "* Activation quantization by discretizing accumulated values\n",
        "* Other features can be factored in much the same way, e.g., conductance drift, non-uniform quantization with ADCs, partial digital summation, etc."
      ],
      "metadata": {
        "id": "oPnlZxqd2KQf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "That's all folks!"
      ],
      "metadata": {
        "id": "pNrFs3ro-xUm"
      }
    }
  ]
}